{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DIR = './data/target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Config / Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "num_classes = 50\n",
    "shift_cls = 0\n",
    "\n",
    "model_path = './checkpoints/ir-model-01.pt'\n",
    "model_state_dict_path = './checkpoints/ir-model_state_dict-01.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_threshould = 80.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrDataset(Dataset):\n",
    "    def __init__(self, spectra, transform=None):\n",
    "        self.spectra = spectra\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.spectra.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        xs = self.spectra[idx]\n",
    "        xs = torch.from_numpy(xs).float()\n",
    "        sample = { \n",
    "            'xs': xs\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(TARGET_DIR + '/df_valid.pk')\n",
    "row_count = df.shape[0]\n",
    "\n",
    "target = df['spectrum'].values\n",
    "target = np.hstack(target).squeeze()\n",
    "target = np.reshape(target, (row_count, 1, -1))\n",
    "\n",
    "valid_dataset = IrDataset(spectra=target)\n",
    "valid_ys = df.iloc[:, 2:52].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(TARGET_DIR + '/df_test.pk')\n",
    "row_count = df.shape[0]\n",
    "\n",
    "target = df['spectrum'].values\n",
    "target = np.hstack(target).squeeze()\n",
    "target = np.reshape(target, (row_count, 1, -1))\n",
    "\n",
    "test_dataset = IrDataset(spectra=target)\n",
    "test_ys = df.iloc[:, 2:52].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(valid_dataset, batch_size=len(valid_dataset), shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(TARGET_DIR + '/df_train.pk')\n",
    "df_valid = pd.read_pickle(TARGET_DIR + '/df_valid.pk')\n",
    "df_test = pd.read_pickle(TARGET_DIR + '/df_test.pk')\n",
    "\n",
    "df_train_col_names = df_train.columns.values.tolist()[2:52]\n",
    "df_valid_col_names = df_valid.columns.values.tolist()[2:52]\n",
    "df_test_col_names = df_test.columns.values.tolist()[2:52]\n",
    "for idx in range(50):\n",
    "    if df_train_col_names[idx] == df_valid_col_names[idx] and df_valid_col_names[idx] == df_test_col_names[idx]:\n",
    "        continue\n",
    "    print('!!!', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CO',\n",
       " 'cOC',\n",
       " 'COC(-,:C)=O',\n",
       " 'cnc',\n",
       " 'cCl',\n",
       " 'cO',\n",
       " 'CCl',\n",
       " 'CC(-,:C)=O',\n",
       " 'cBr',\n",
       " 'c[N&+](=O)[O&-]',\n",
       " 'cC(-,:C)=O',\n",
       " 'C=CC',\n",
       " 'cN',\n",
       " 'cC(=O)OC',\n",
       " 'COC',\n",
       " 'CF',\n",
       " 'CBr',\n",
       " 'coc',\n",
       " 'cF',\n",
       " 'CC(=O)O',\n",
       " 'c=O',\n",
       " 'c[n&H1]c',\n",
       " 'csc',\n",
       " 'cC=O',\n",
       " 'CNC',\n",
       " 'CN',\n",
       " 'CN(-,:C)C',\n",
       " 'cC#N',\n",
       " 'cn(-,:c)C',\n",
       " 'cC(=O)O',\n",
       " 'CC=C(-,:C)C',\n",
       " 'CC#N',\n",
       " 'cNC(-,:C)=O',\n",
       " 'cNC',\n",
       " 'C/C=C/C',\n",
       " 'CC=CC',\n",
       " 'C=C(-,:C)C',\n",
       " 'C#CC',\n",
       " 'cC(-,:c)=O',\n",
       " 'cN(-,:C)C',\n",
       " 'CC(=O)OC',\n",
       " 'CC#CC',\n",
       " 'cI',\n",
       " 'CNC(-,:C)=O',\n",
       " 'cC=Cc',\n",
       " 'c-n(-,:c)c',\n",
       " 'cnn(-,:c)C',\n",
       " 'cnnc',\n",
       " 'cP(-,:c)c',\n",
       " 'CS']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=2, kernel_size=11, stride=1, padding=5)\n",
    "        self.conv1_bn = nn.BatchNorm1d(2)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.conv2 = nn.Conv1d(in_channels=2, out_channels=4, kernel_size=11, stride=1, padding=5)\n",
    "        self.conv2_bn = nn.BatchNorm1d(4)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.conv3 = nn.Conv1d(in_channels=4, out_channels=8, kernel_size=11, stride=1, padding=5)\n",
    "        self.conv3_bn = nn.BatchNorm1d(8)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc1 = nn.Linear(3400, 1000)\n",
    "        self.fc1_bn = nn.BatchNorm1d(1000)\n",
    "        self.dropout_fc1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(1000, 250)\n",
    "        self.fc2_bn = nn.BatchNorm1d(250)\n",
    "        self.dropout_fc2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(250, 64)\n",
    "        self.fc3_bn = nn.BatchNorm1d(64)\n",
    "        self.dropout_fc3 = nn.Dropout(dropout_rate)\n",
    "        self.fc4 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.conv1_bn(\n",
    "            F.relu(\n",
    "                self.conv1(x)\n",
    "            )\n",
    "        )\n",
    "        x = self.dropout1(z)\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        z = self.conv2_bn(\n",
    "            F.relu(\n",
    "                self.conv2(x)\n",
    "            )\n",
    "        )\n",
    "        x = self.dropout2(z)\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        z = self.conv3_bn(\n",
    "            F.relu(\n",
    "                self.conv3(x)\n",
    "            )\n",
    "        )\n",
    "        x = self.dropout3(z)\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = self.dropout_fc1(x)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.dropout_fc2(x)\n",
    "        x = F.relu(self.fc3_bn(self.fc3(x)))\n",
    "        x = self.dropout_fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        output = torch.sigmoid(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "# criterion = nn.BCELoss(reduction='none')\n",
    "\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train / Test processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_results = []\n",
    "\n",
    "# def train_process(model, device, data_loader, criterion, optimizer, epoch):\n",
    "#     model.train()\n",
    "    \n",
    "#     total_loss = 0.0\n",
    "#     counter = 0.0\n",
    "#     for batch_idx, data in enumerate(data_loader):\n",
    "#         xs, ys, ws = data['xs'].to(device), data['ys'].to(device), data['ws'].to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         output = model(xs)\n",
    "#         loss = criterion(output, ys)\n",
    "#         loss = (loss * ws).mean()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "#         counter += 1.0\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         optimizer.step()\n",
    "    \n",
    "#     train_results.append((epoch, total_loss / counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_verify_loss = 10000\n",
    "\n",
    "def make_predict_and_bundle_answer(model, device, data_loader, ys):\n",
    "    model.eval()\n",
    "\n",
    "    ans = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            xs = data['xs'].to(device)\n",
    "            output = model(xs)\n",
    "            output = output.cpu().numpy()\n",
    "\n",
    "            ans.append((output, ys))\n",
    "    if len(ans) is not 1:\n",
    "        print('ERROR: data_loader should be 1 batch!')\n",
    "        return False\n",
    "    return ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     train_process(model, device, train_loader, criterion, optimizer, epoch)\n",
    "#     verify_process(model, device, valid_loader, criterion, epoch)\n",
    "#     if epoch % log_interval == 0:\n",
    "#         print(\n",
    "#             'Epoch: {:0>3d}; Train Loss: {:.5f}; Validation Loss: {:.5f}'.format(\n",
    "#                 epoch, \n",
    "#                 train_results[-1][1], \n",
    "#                 verify_results[-1][1]\n",
    "#             )\n",
    "#         )\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss = [a for e, a in train_results]\n",
    "# train_eps = [e for e, a in train_results]\n",
    "# valid_loss = [a for e, a in verify_results]\n",
    "# valid_eps = [e for e, a in verify_results]\n",
    "# plt.plot(train_eps, train_loss, 'b-')\n",
    "# plt.plot(valid_eps, valid_loss, 'r.')\n",
    "# plt.show()\n",
    "# min(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(1, 2, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "  (conv1_bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv1d(2, 4, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "  (conv2_bn): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (conv3): Conv1d(4, 8, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "  (conv3_bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=3400, out_features=1000, bias=True)\n",
       "  (fc1_bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout_fc1): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=1000, out_features=250, bias=True)\n",
       "  (fc2_bn): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout_fc2): Dropout(p=0.2, inplace=False)\n",
       "  (fc3): Linear(in_features=250, out_features=64, bias=True)\n",
       "  (fc3_bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout_fc3): Dropout(p=0.2, inplace=False)\n",
       "  (fc4): Linear(in_features=64, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_location='cpu'\n",
    "\n",
    "loaded_model = torch.load(model_path, map_location=map_location)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(cls_idx, yhs, ys):\n",
    "    t_total, t_correct, t_wrong = 0, 0, 0\n",
    "    f_total, f_correct, f_wrong = 0, 0, 0\n",
    "\n",
    "    for idx in range(len(ys)):\n",
    "        yh, y = yhs[idx][cls_idx], ys[idx][cls_idx]\n",
    "        if y == 1:\n",
    "            t_total += 1\n",
    "            if yh >= 0.5:\n",
    "                t_correct += 1\n",
    "            else:\n",
    "                t_wrong += 1\n",
    "        elif y == 0:\n",
    "            f_total += 1\n",
    "            if yh < 0.5:\n",
    "                f_correct += 1\n",
    "            else:\n",
    "                f_wrong += 1\n",
    "        else:\n",
    "            t_wrong += 1\n",
    "            f_wrong += 1\n",
    "    t_acc = t_correct * 100.0 / t_total\n",
    "    f_acc = f_correct * 100.0 / f_total\n",
    "    return t_acc, f_acc\n",
    "\n",
    "\n",
    "def print_result(cls_idx, valid_t_acc, valid_f_acc, test_t_acc, test_f_acc):\n",
    "    print(\n",
    "        'FG{:0>2d}({}) ValidTrueAcc = {:0.0f}%({}); ValidFalseAcc = {:.0f}%({}); TestTrueAcc = {:0.0f}%({}); TestFalseAcc = {:.0f}%({}); {}'.format(\n",
    "            cls_idx,\n",
    "            'O' if valid_t_acc >= pass_threshould and valid_f_acc >= pass_threshould and test_t_acc >= pass_threshould and test_f_acc >= pass_threshould else 'X',\n",
    "            valid_t_acc,\n",
    "            'O' if valid_t_acc >= pass_threshould else 'X',\n",
    "            valid_f_acc,\n",
    "            'O' if valid_f_acc >= pass_threshould else 'X',\n",
    "            test_t_acc,\n",
    "            'O' if test_t_acc >= pass_threshould else 'X',\n",
    "            test_f_acc,\n",
    "            'O' if test_f_acc >= pass_threshould else 'X',\n",
    "            df_test_col_names[cls_idx]\n",
    "            \n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG00(O) ValidTrueAcc = 89%(O); ValidFalseAcc = 94%(O); TestTrueAcc = 96%(O); TestFalseAcc = 95%(O); CO\n",
      "FG01(O) ValidTrueAcc = 86%(O); ValidFalseAcc = 87%(O); TestTrueAcc = 83%(O); TestFalseAcc = 87%(O); cOC\n",
      "FG02(O) ValidTrueAcc = 97%(O); ValidFalseAcc = 93%(O); TestTrueAcc = 97%(O); TestFalseAcc = 93%(O); COC(-,:C)=O\n",
      "FG03(X) ValidTrueAcc = 88%(O); ValidFalseAcc = 83%(O); TestTrueAcc = 89%(O); TestFalseAcc = 80%(X); cnc\n",
      "FG04(X) ValidTrueAcc = 89%(O); ValidFalseAcc = 80%(O); TestTrueAcc = 91%(O); TestFalseAcc = 78%(X); cCl\n",
      "FG05(O) ValidTrueAcc = 92%(O); ValidFalseAcc = 95%(O); TestTrueAcc = 88%(O); TestFalseAcc = 93%(O); cO\n",
      "FG06(O) ValidTrueAcc = 89%(O); ValidFalseAcc = 90%(O); TestTrueAcc = 90%(O); TestFalseAcc = 90%(O); CCl\n",
      "FG07(O) ValidTrueAcc = 84%(O); ValidFalseAcc = 91%(O); TestTrueAcc = 97%(O); TestFalseAcc = 90%(O); CC(-,:C)=O\n",
      "FG08(X) ValidTrueAcc = 81%(O); ValidFalseAcc = 77%(X); TestTrueAcc = 91%(O); TestFalseAcc = 76%(X); cBr\n",
      "FG09(O) ValidTrueAcc = 90%(O); ValidFalseAcc = 96%(O); TestTrueAcc = 94%(O); TestFalseAcc = 96%(O); c[N&+](=O)[O&-]\n",
      "FG10(O) ValidTrueAcc = 96%(O); ValidFalseAcc = 94%(O); TestTrueAcc = 94%(O); TestFalseAcc = 94%(O); cC(-,:C)=O\n",
      "FG11(O) ValidTrueAcc = 87%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 86%(O); TestFalseAcc = 96%(O); C=CC\n",
      "FG12(O) ValidTrueAcc = 92%(O); ValidFalseAcc = 95%(O); TestTrueAcc = 96%(O); TestFalseAcc = 94%(O); cN\n",
      "FG13(O) ValidTrueAcc = 96%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 85%(O); TestFalseAcc = 98%(O); cC(=O)OC\n",
      "FG14(O) ValidTrueAcc = 93%(O); ValidFalseAcc = 96%(O); TestTrueAcc = 100%(O); TestFalseAcc = 96%(O); COC\n",
      "FG15(O) ValidTrueAcc = 83%(O); ValidFalseAcc = 90%(O); TestTrueAcc = 97%(O); TestFalseAcc = 92%(O); CF\n",
      "FG16(O) ValidTrueAcc = 88%(O); ValidFalseAcc = 89%(O); TestTrueAcc = 80%(O); TestFalseAcc = 87%(O); CBr\n",
      "FG17(O) ValidTrueAcc = 81%(O); ValidFalseAcc = 96%(O); TestTrueAcc = 80%(O); TestFalseAcc = 96%(O); coc\n",
      "FG18(X) ValidTrueAcc = 88%(O); ValidFalseAcc = 91%(O); TestTrueAcc = 77%(X); TestFalseAcc = 91%(O); cF\n",
      "FG19(O) ValidTrueAcc = 80%(O); ValidFalseAcc = 100%(O); TestTrueAcc = 84%(O); TestFalseAcc = 100%(O); CC(=O)O\n",
      "FG20(O) ValidTrueAcc = 94%(O); ValidFalseAcc = 95%(O); TestTrueAcc = 88%(O); TestFalseAcc = 95%(O); c=O\n",
      "FG21(X) ValidTrueAcc = 94%(O); ValidFalseAcc = 96%(O); TestTrueAcc = 72%(X); TestFalseAcc = 95%(O); c[n&H1]c\n",
      "FG22(X) ValidTrueAcc = 79%(X); ValidFalseAcc = 89%(O); TestTrueAcc = 57%(X); TestFalseAcc = 90%(O); csc\n",
      "FG23(X) ValidTrueAcc = 100%(O); ValidFalseAcc = 95%(O); TestTrueAcc = 79%(X); TestFalseAcc = 96%(O); cC=O\n",
      "FG24(O) ValidTrueAcc = 82%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 92%(O); TestFalseAcc = 96%(O); CNC\n",
      "FG25(X) ValidTrueAcc = 75%(X); ValidFalseAcc = 99%(O); TestTrueAcc = 100%(O); TestFalseAcc = 99%(O); CN\n",
      "FG26(O) ValidTrueAcc = 92%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 92%(O); TestFalseAcc = 96%(O); CN(-,:C)C\n",
      "FG27(O) ValidTrueAcc = 92%(O); ValidFalseAcc = 94%(O); TestTrueAcc = 92%(O); TestFalseAcc = 94%(O); cC#N\n",
      "FG28(O) ValidTrueAcc = 85%(O); ValidFalseAcc = 94%(O); TestTrueAcc = 100%(O); TestFalseAcc = 95%(O); cn(-,:c)C\n",
      "FG29(X) ValidTrueAcc = 73%(X); ValidFalseAcc = 98%(O); TestTrueAcc = 91%(O); TestFalseAcc = 97%(O); cC(=O)O\n",
      "FG30(O) ValidTrueAcc = 90%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 91%(O); TestFalseAcc = 97%(O); CC=C(-,:C)C\n",
      "FG31(X) ValidTrueAcc = 64%(X); ValidFalseAcc = 93%(O); TestTrueAcc = 64%(X); TestFalseAcc = 92%(O); CC#N\n",
      "FG32(O) ValidTrueAcc = 91%(O); ValidFalseAcc = 95%(O); TestTrueAcc = 100%(O); TestFalseAcc = 96%(O); cNC(-,:C)=O\n",
      "FG33(O) ValidTrueAcc = 90%(O); ValidFalseAcc = 94%(O); TestTrueAcc = 90%(O); TestFalseAcc = 95%(O); cNC\n",
      "FG34(X) ValidTrueAcc = 88%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 71%(X); TestFalseAcc = 97%(O); C/C=C/C\n",
      "FG35(O) ValidTrueAcc = 90%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 80%(O); TestFalseAcc = 98%(O); CC=CC\n",
      "FG36(O) ValidTrueAcc = 88%(O); ValidFalseAcc = 98%(O); TestTrueAcc = 89%(O); TestFalseAcc = 98%(O); C=C(-,:C)C\n",
      "FG37(X) ValidTrueAcc = 88%(O); ValidFalseAcc = 100%(O); TestTrueAcc = 78%(X); TestFalseAcc = 100%(O); C#CC\n",
      "FG38(X) ValidTrueAcc = 100%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 60%(X); TestFalseAcc = 96%(O); cC(-,:c)=O\n",
      "FG39(O) ValidTrueAcc = 100%(O); ValidFalseAcc = 92%(O); TestTrueAcc = 89%(O); TestFalseAcc = 92%(O); cN(-,:C)C\n",
      "FG40(O) ValidTrueAcc = 90%(O); ValidFalseAcc = 99%(O); TestTrueAcc = 100%(O); TestFalseAcc = 99%(O); CC(=O)OC\n",
      "FG41(O) ValidTrueAcc = 89%(O); ValidFalseAcc = 96%(O); TestTrueAcc = 100%(O); TestFalseAcc = 97%(O); CC#CC\n",
      "FG42(X) ValidTrueAcc = 44%(X); ValidFalseAcc = 94%(O); TestTrueAcc = 75%(X); TestFalseAcc = 93%(O); cI\n",
      "FG43(O) ValidTrueAcc = 88%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 88%(O); TestFalseAcc = 97%(O); CNC(-,:C)=O\n",
      "FG44(O) ValidTrueAcc = 100%(O); ValidFalseAcc = 99%(O); TestTrueAcc = 86%(O); TestFalseAcc = 99%(O); cC=Cc\n",
      "FG45(X) ValidTrueAcc = 78%(X); ValidFalseAcc = 99%(O); TestTrueAcc = 56%(X); TestFalseAcc = 99%(O); c-n(-,:c)c\n",
      "FG46(O) ValidTrueAcc = 88%(O); ValidFalseAcc = 97%(O); TestTrueAcc = 100%(O); TestFalseAcc = 98%(O); cnn(-,:c)C\n",
      "FG47(X) ValidTrueAcc = 100%(O); ValidFalseAcc = 98%(O); TestTrueAcc = 50%(X); TestFalseAcc = 97%(O); cnnc\n",
      "FG48(O) ValidTrueAcc = 100%(O); ValidFalseAcc = 98%(O); TestTrueAcc = 100%(O); TestFalseAcc = 99%(O); cP(-,:c)c\n",
      "FG49(X) ValidTrueAcc = 75%(X); ValidFalseAcc = 97%(O); TestTrueAcc = 88%(O); TestFalseAcc = 96%(O); CS\n",
      "number of useful FGs in valid sets (t_acc and f_acc are more than 80.0%) =  33\n"
     ]
    }
   ],
   "source": [
    "valid_yhs, valid_ys = make_predict_and_bundle_answer(loaded_model, device, valid_loader, valid_ys)\n",
    "test_yhs, test_ys = make_predict_and_bundle_answer(loaded_model, device, test_loader, test_ys)\n",
    "\n",
    "fail_fg_idxs = []\n",
    "\n",
    "pass_count = 0\n",
    "dict_fg_acc_results = {}\n",
    "for cls_idx in range(num_classes):\n",
    "    valid_t_acc, valid_f_acc = calc_accuracy(cls_idx, valid_yhs, valid_ys)\n",
    "    test_t_acc, test_f_acc = calc_accuracy(cls_idx, test_yhs, test_ys)\n",
    "    print_result(cls_idx, valid_t_acc, valid_f_acc, test_t_acc, test_f_acc)\n",
    "    if valid_t_acc >= pass_threshould and valid_f_acc >= pass_threshould and test_t_acc >= pass_threshould and test_f_acc >= pass_threshould:\n",
    "        pass_count += 1\n",
    "        test_balanced_acc = (test_t_acc + test_f_acc) / 2.0\n",
    "        dict_fg_acc_results[df_test_col_names[cls_idx]] = {\n",
    "            'bacc': test_balanced_acc,\n",
    "            'output_idx': cls_idx,\n",
    "        }\n",
    "    else:\n",
    "        fail_fg_idxs.append(cls_idx)\n",
    "        \n",
    "print(\n",
    "    'number of useful FGs in valid sets (t_acc and f_acc are more than {}%) = '.format(pass_threshould), \n",
    "    pass_count,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CO': {'bacc': 95.50769437537801, 'output_idx': 0},\n",
       " 'cOC': {'bacc': 85.05103380989905, 'output_idx': 1},\n",
       " 'COC(-,:C)=O': {'bacc': 95.19251568245727, 'output_idx': 2},\n",
       " 'cO': {'bacc': 90.88144881047847, 'output_idx': 5},\n",
       " 'CCl': {'bacc': 89.92131616595137, 'output_idx': 6},\n",
       " 'CC(-,:C)=O': {'bacc': 93.48700495049505, 'output_idx': 7},\n",
       " 'c[N&+](=O)[O&-]': {'bacc': 94.65554948059048, 'output_idx': 9},\n",
       " 'cC(-,:C)=O': {'bacc': 93.66684891561874, 'output_idx': 10},\n",
       " 'C=CC': {'bacc': 90.92034968431278, 'output_idx': 11},\n",
       " 'cN': {'bacc': 95.26069921639542, 'output_idx': 12},\n",
       " 'cC(=O)OC': {'bacc': 91.36191947806678, 'output_idx': 13},\n",
       " 'COC': {'bacc': 97.96348314606742, 'output_idx': 14},\n",
       " 'CF': {'bacc': 94.31358721203574, 'output_idx': 15},\n",
       " 'CBr': {'bacc': 83.41736694677871, 'output_idx': 16},\n",
       " 'coc': {'bacc': 88.109243697479, 'output_idx': 17},\n",
       " 'CC(=O)O': {'bacc': 91.8969298245614, 'output_idx': 19},\n",
       " 'c=O': {'bacc': 91.83232849926674, 'output_idx': 20},\n",
       " 'CNC': {'bacc': 94.22547149819877, 'output_idx': 24},\n",
       " 'CN(-,:C)C': {'bacc': 94.36321254503073, 'output_idx': 26},\n",
       " 'cC#N': {'bacc': 93.05467260012715, 'output_idx': 27},\n",
       " 'cn(-,:c)C': {'bacc': 97.45529573590096, 'output_idx': 28},\n",
       " 'CC=C(-,:C)C': {'bacc': 93.73751248751249, 'output_idx': 30},\n",
       " 'cNC(-,:C)=O': {'bacc': 97.93388429752066, 'output_idx': 32},\n",
       " 'cNC': {'bacc': 92.2565157750343, 'output_idx': 33},\n",
       " 'CC=CC': {'bacc': 88.90260631001371, 'output_idx': 35},\n",
       " 'C=C(-,:C)C': {'bacc': 93.6910197869102, 'output_idx': 36},\n",
       " 'cN(-,:C)C': {'bacc': 90.60882800608829, 'output_idx': 39},\n",
       " 'CC(=O)OC': {'bacc': 99.38356164383562, 'output_idx': 40},\n",
       " 'CC#CC': {'bacc': 98.42465753424658, 'output_idx': 41},\n",
       " 'CNC(-,:C)=O': {'bacc': 92.38201094391245, 'output_idx': 43},\n",
       " 'cC=Cc': {'bacc': 92.2423887587822, 'output_idx': 44},\n",
       " 'cnn(-,:c)C': {'bacc': 99.04240766073872, 'output_idx': 46},\n",
       " 'cP(-,:c)c': {'bacc': 99.45280437756497, 'output_idx': 48}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_fg_acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_dict_fg_acc_results = './checkpoints/dict_fg_acc_results.pk'\n",
    "with open(fn_dict_fg_acc_results, 'wb') as file:\n",
    "    pickle.dump(dict_fg_acc_results, file)\n",
    "    \n",
    "loaded_dict_fg_acc_results = None\n",
    "with open(fn_dict_fg_acc_results, 'rb') as file:\n",
    "    loaded_dict_fg_acc_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CO': {'bacc': 95.50769437537801, 'output_idx': 0},\n",
       " 'cOC': {'bacc': 85.05103380989905, 'output_idx': 1},\n",
       " 'COC(-,:C)=O': {'bacc': 95.19251568245727, 'output_idx': 2},\n",
       " 'cO': {'bacc': 90.88144881047847, 'output_idx': 5},\n",
       " 'CCl': {'bacc': 89.92131616595137, 'output_idx': 6},\n",
       " 'CC(-,:C)=O': {'bacc': 93.48700495049505, 'output_idx': 7},\n",
       " 'c[N&+](=O)[O&-]': {'bacc': 94.65554948059048, 'output_idx': 9},\n",
       " 'cC(-,:C)=O': {'bacc': 93.66684891561874, 'output_idx': 10},\n",
       " 'C=CC': {'bacc': 90.92034968431278, 'output_idx': 11},\n",
       " 'cN': {'bacc': 95.26069921639542, 'output_idx': 12},\n",
       " 'cC(=O)OC': {'bacc': 91.36191947806678, 'output_idx': 13},\n",
       " 'COC': {'bacc': 97.96348314606742, 'output_idx': 14},\n",
       " 'CF': {'bacc': 94.31358721203574, 'output_idx': 15},\n",
       " 'CBr': {'bacc': 83.41736694677871, 'output_idx': 16},\n",
       " 'coc': {'bacc': 88.109243697479, 'output_idx': 17},\n",
       " 'CC(=O)O': {'bacc': 91.8969298245614, 'output_idx': 19},\n",
       " 'c=O': {'bacc': 91.83232849926674, 'output_idx': 20},\n",
       " 'CNC': {'bacc': 94.22547149819877, 'output_idx': 24},\n",
       " 'CN(-,:C)C': {'bacc': 94.36321254503073, 'output_idx': 26},\n",
       " 'cC#N': {'bacc': 93.05467260012715, 'output_idx': 27},\n",
       " 'cn(-,:c)C': {'bacc': 97.45529573590096, 'output_idx': 28},\n",
       " 'CC=C(-,:C)C': {'bacc': 93.73751248751249, 'output_idx': 30},\n",
       " 'cNC(-,:C)=O': {'bacc': 97.93388429752066, 'output_idx': 32},\n",
       " 'cNC': {'bacc': 92.2565157750343, 'output_idx': 33},\n",
       " 'CC=CC': {'bacc': 88.90260631001371, 'output_idx': 35},\n",
       " 'C=C(-,:C)C': {'bacc': 93.6910197869102, 'output_idx': 36},\n",
       " 'cN(-,:C)C': {'bacc': 90.60882800608829, 'output_idx': 39},\n",
       " 'CC(=O)OC': {'bacc': 99.38356164383562, 'output_idx': 40},\n",
       " 'CC#CC': {'bacc': 98.42465753424658, 'output_idx': 41},\n",
       " 'CNC(-,:C)=O': {'bacc': 92.38201094391245, 'output_idx': 43},\n",
       " 'cC=Cc': {'bacc': 92.2423887587822, 'output_idx': 44},\n",
       " 'cnn(-,:c)C': {'bacc': 99.04240766073872, 'output_idx': 46},\n",
       " 'cP(-,:c)c': {'bacc': 99.45280437756497, 'output_idx': 48}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict_fg_acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_dict_fg_acc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(loaded_model.state_dict(), model_state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 8, 18, 21, 22, 23, 25, 29, 31, 34, 37, 38, 42, 45, 47, 49]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_fg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fail_fg_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-ir-02",
   "language": "python",
   "name": "deep-ir-02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
