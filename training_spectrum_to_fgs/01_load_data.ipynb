{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please copy `nist` data to `./data/` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nist data](./assets/nist.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json \n",
    "import nmrglue as ng\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.carrier import SpectraCarrier\n",
    "import lib.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.09.1\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "print(rdkit.__version__)\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load spectrum from NIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_begin_idx = 600\n",
    "curve_correction_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "SOURCE_DIR = './data/source'\n",
    "TARGET_DIR = './data/target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train_df = '{}/train_df.pk'.format(SOURCE_DIR)\n",
    "fn_valid_df = '{}/valid_df.pk'.format(SOURCE_DIR)\n",
    "fn_test_df = '{}/test_df.pk'.format(SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_train_df = None\n",
    "with open(fn_train_df, 'rb') as file:\n",
    "    loaded_train_df = pickle.load(file)\n",
    "    \n",
    "loaded_valid_df = None\n",
    "with open(fn_valid_df, 'rb') as file:\n",
    "    loaded_valid_df = pickle.load(file)\n",
    "    \n",
    "loaded_test_df = None\n",
    "with open(fn_test_df, 'rb') as file:\n",
    "    loaded_test_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order(x_i, y_i):\n",
    "    x_o = x_i\n",
    "    y_o = y_i\n",
    "\n",
    "    first_x = x_i[0]\n",
    "    last_x = x_i[-1]\n",
    "    if first_x > last_x:\n",
    "        x_o = x_o[::-1]\n",
    "        y_o = y_o[::-1]\n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def concat_boundary(x_i, y_i):\n",
    "    x_head = np.array([0.0])\n",
    "    x_tail = np.array([4000.0])\n",
    "    x_o = np.concatenate([x_head, x_i, x_tail])\n",
    "\n",
    "    y_head = np.array([y_i[0]])\n",
    "    y_tail = np.array([y_i[-1]])\n",
    "    y_o = np.concatenate([y_head, y_i, y_tail])\n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def sampling(x_i, y_i):\n",
    "    f = interpolate.interp1d(x_i, y_i)\n",
    "    x_o = np.linspace(0, 3999, 4000, endpoint=True)\n",
    "    y_o = f(x_o)\n",
    "    return x_o[curve_begin_idx:], y_o[curve_begin_idx:]\n",
    "\n",
    "\n",
    "def normalize(x_i, y_i):\n",
    "    max_y = np.max(y_i)\n",
    "    min_y = np.min(y_i)\n",
    "    height = max_y - min_y\n",
    "\n",
    "    x_o = x_i\n",
    "    y_o = (y_i - min_y) / height\n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def use_transmission(x_i, y_i):\n",
    "    x_o = x_i\n",
    "    y_o = y_i\n",
    "    \n",
    "    y_median = np.median(y_i)\n",
    "    if y_median < 0.5:\n",
    "        y_o = y_i # 1 - y_i\n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def chop(x_i, y_i):\n",
    "    x_o = x_i[0:]\n",
    "    y_o = y_i[0:]\n",
    "    \n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def read_spectrum(path):\n",
    "    sc = SpectraCarrier(path)\n",
    "\n",
    "    # original\n",
    "    x_orig, y_orig = order(sc.x, sc.y)\n",
    "\n",
    "    # concatenate\n",
    "    x_basis, y_basis = concat_boundary(x_orig, y_orig)\n",
    "\n",
    "    # interpolate\n",
    "    x_new, y_new = sampling(x_basis, y_basis)\n",
    "    y_new = y_new ** curve_correction_factor\n",
    "\n",
    "    # normalized\n",
    "    x_new_norm, y_new_norm = normalize(x_new, y_new)\n",
    "\n",
    "    # absorption\n",
    "    x_new_norm_abs, y_new_norm_abs = use_transmission(x_new_norm, y_new_norm)\n",
    "\n",
    "    # chop\n",
    "    x_nnac, y_nnac = chop(x_new_norm_abs, y_new_norm_abs)\n",
    "    \n",
    "    return x_nnac, y_nnac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in loaded_train_df.iterrows():\n",
    "    if len(row['fn']) < 30:\n",
    "        done = False\n",
    "        fname = '{}/nist/Individual_Files/EPA/DX/{}.DX'.format(DATA_DIR, row['fn'])\n",
    "        if os.path.isfile(fname):\n",
    "            _, y = read_spectrum(fname)\n",
    "            loaded_train_df.at[idx, 'spectrum'] = y\n",
    "            done = True\n",
    "        fname = '{}/nist/Individual_Files/NIST/DX/{}.DX'.format(DATA_DIR, row['fn'])\n",
    "        if not done and os.path.isfile(fname):\n",
    "            _, y = read_spectrum(fname)\n",
    "            loaded_train_df.at[idx, 'spectrum'] = y\n",
    "            \n",
    "for idx, row in loaded_valid_df.iterrows():\n",
    "    if len(row['fn']) < 30:\n",
    "        done = False\n",
    "        fname = '{}/nist/Individual_Files/EPA/DX/{}.DX'.format(DATA_DIR, row['fn'])\n",
    "        if os.path.isfile(fname):\n",
    "            _, y = read_spectrum(fname)\n",
    "            loaded_valid_df.at[idx, 'spectrum'] = y\n",
    "            done = True\n",
    "        fname = '{}/nist/Individual_Files/NIST/DX/{}.DX'.format(DATA_DIR, row['fn'])\n",
    "        if not done and os.path.isfile(fname):\n",
    "            _, y = read_spectrum(fname)\n",
    "            loaded_valid_df.at[idx, 'spectrum'] = y\n",
    "            \n",
    "for idx, row in loaded_test_df.iterrows():\n",
    "    if len(row['fn']) < 30:\n",
    "        done = False\n",
    "        fname = '{}/nist/Individual_Files/EPA/DX/{}.DX'.format(DATA_DIR, row['fn'])\n",
    "        if os.path.isfile(fname):\n",
    "            _, y = read_spectrum(fname)\n",
    "            loaded_test_df.at[idx, 'spectrum'] = y\n",
    "            done = True\n",
    "        fname = '{}/nist/Individual_Files/NIST/DX/{}.DX'.format(DATA_DIR, row['fn'])\n",
    "        if not done and os.path.isfile(fname):\n",
    "            _, y = read_spectrum(fname)\n",
    "            loaded_test_df.at[idx, 'spectrum'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all spectra.\n",
      "Load all spectra.\n",
      "Load all spectra.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for idx, row in loaded_train_df.iterrows():\n",
    "    if row['spectrum'] is None:\n",
    "        counter += 1\n",
    "print('Load all spectra.' if counter == 0 else 'Some spectra are missing, please check them.')\n",
    "\n",
    "counter = 0\n",
    "for idx, row in loaded_valid_df.iterrows():\n",
    "    if row['spectrum'] is None:\n",
    "        counter += 1\n",
    "print('Load all spectra.' if counter == 0 else 'Some spectra are missing, please check them.')\n",
    "\n",
    "counter = 0\n",
    "for idx, row in loaded_test_df.iterrows():\n",
    "    if row['spectrum'] is None:\n",
    "        counter += 1\n",
    "print('Load all spectra.' if counter == 0 else 'Some spectra are missing, please check them.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train_df = '{}/df_train.pk'.format(TARGET_DIR)\n",
    "fn_valid_df = '{}/df_valid.pk'.format(TARGET_DIR)\n",
    "fn_test_df = '{}/df_test.pk'.format(TARGET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_train_df, 'wb') as file:\n",
    "    pickle.dump(loaded_train_df, file)\n",
    "    \n",
    "with open(fn_valid_df, 'wb') as file:\n",
    "    pickle.dump(loaded_valid_df, file)\n",
    "    \n",
    "with open(fn_test_df, 'wb') as file:\n",
    "    pickle.dump(loaded_test_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NIST spectra into dataframes. Ready to train the model.\n"
     ]
    }
   ],
   "source": [
    "print('Load NIST spectra into dataframes. Ready to train the model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-ir-01",
   "language": "python",
   "name": "deep-ir-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
